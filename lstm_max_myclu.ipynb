{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import sklearn.linear_model as lm\n",
    "import numpy as np\n",
    "np.random.seed(888)\n",
    "from keras.models import Sequential,load_model,Model\n",
    "from keras.layers import Dense,Reshape,Dropout,LSTM,Activation,MaxoutDense\n",
    "from keras.layers.advanced_activations import LeakyReLU,PReLU\n",
    "\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.constraints import nonneg\n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow\n",
    "import keras\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "from sklearn import cluster, datasets, metrics\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5040\n",
      "1680\n",
      "-0.0577850341797 seconds\n"
     ]
    }
   ],
   "source": [
    "oli = pd.read_csv('cleanoutwvd.csv')\n",
    "olier = oli.copy();\n",
    "#去掉當量暫時不用\n",
    "\n",
    "# olier.speed=(olier.speed);olier\n",
    "# olier.YY=olier.YY-16;\n",
    "olier=olier.drop(['YY','day','date','time','direct','lane','eqflow','fakeornot','realvd'],axis=1);olier\n",
    "# olier['serial'] = olier.index\n",
    "\n",
    "# normalize the dataset\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# olier = scaler.fit_transform(olier)\n",
    "# olierc=pd.DataFrame(olier,columns=['sortby','speed','accu'])\n",
    "\n",
    "# move speed to the end\n",
    "\n",
    "olierclo = olier.columns.tolist()\n",
    "olier=olier[olierclo[:-2]+olierclo[-1:]+olierclo[-2:-1]]\n",
    "# olier= olier[olierclo[-1:]+olierclo[:1]+olierclo[2:3]+olierclo[1:2]]; # 有serial時的speed\n",
    "\n",
    "#0225version\n",
    "def cleanout(inp,i):\n",
    "    dfvdi= inp.where(inp['sortby']==i).dropna();\n",
    "\n",
    "    outp = dfvdi.copy()\n",
    "    # 某個時間要把fakeornot去掉 \n",
    "    outpp = outp.values.astype('float32')\n",
    "    # 分出train 跟test\n",
    "    train_size = int(len(outpp) * 0.75)\n",
    "    test_size = len(outpp) - train_size\n",
    "    train, test = outpp[0:train_size,:], outpp[train_size:len(outpp),:]\n",
    "    if (len(train)%168 != 0) or (len(test)%168 != 0) :\n",
    "        train=train[:-(len(train)%168)]\n",
    "        test=test[:-(len(test)%168)]\n",
    "        \n",
    "    return train,test\n",
    "\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# sortbylist=olierc['sortby'].unique().tolist()\n",
    "\n",
    "sortbylist=[3,4,6,8,29,38]\n",
    "\n",
    "\n",
    "tralist = []\n",
    "teslist = []\n",
    "\n",
    "for i in [sortbylist[0]]:\n",
    "    temptra,temptes=cleanout(olier,i)\n",
    "    #train\n",
    "    for ele in temptra.tolist():\n",
    "        tralist.append(ele)\n",
    "    #test\n",
    "    for ele3 in temptes.tolist():\n",
    "        teslist.append(ele3)\n",
    "\n",
    "cluster01tra=np.array(tralist)\n",
    "print len(cluster01tra)\n",
    "cluster01tes=np.array(teslist)\n",
    "print len(cluster01tes)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "cluster01tra = scaler.fit_transform(cluster01tra)\n",
    "cluster01tes = scaler.fit_transform(cluster01tes)\n",
    "\n",
    "# cluster01tra = preprocessing.scale(cluster01tra)\n",
    "# cluster01tes = preprocessing.scale(cluster01tes)\n",
    "\n",
    "\n",
    "print(start - time.time()),'seconds'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5040, 1680)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#起始隨機子\n",
    "np.random.seed(888)\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(0,len(dataset)-look_back-1,look_back):\n",
    "        a = dataset[i:(i+look_back), 0:nort]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back:i+look_back+look_back, nort-1])\n",
    "#     return dataX,dataY\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# 看資料有幾個欄位就寫幾\n",
    "nort = 3\n",
    "# magic number\n",
    "look_back = 168\n",
    "# cut off remainder\n",
    "train = cluster01tra\n",
    "test = cluster01tes\n",
    "# check data lenth when cut off remainder\n",
    "print(len(train), len(test))\n",
    "\n",
    "# seperate data to input\"X\" and output\"Y\"\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 3))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 3))\n",
    "\n",
    "# create and fit Multilayer Perceptron model\n",
    "model = Sequential()\n",
    "# model = Model(input=look_back*nort,output=[look_back,2])\n",
    "\n",
    "\n",
    "model.add(LSTM(168, input_shape=(look_back,nort), return_sequences=True))\n",
    "model.add(Activation(\"linear\"))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(LSTM(168, input_shape=(look_back,nort)))\n",
    "model.add(Activation(\"linear\"))\n",
    "model.add(Dropout(0.35))\n",
    "# model.add(MaxoutDense(256, init='uniform',W_regularizer = l2(0.000017)))\n",
    "# model.add(LeakyReLU(0.00017))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(look_back,W_constraint=nonneg()))\n",
    "model.add(Activation(\"linear\")) \n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, nb_epoch=30, batch_size=336, verbose=0)\n",
    "\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "print(start - time.time()),'seconds'\n",
    "\n",
    "# pre = testPredict.reshape(len(testPredict)*len(testPredict[0]),)\n",
    "# ori = testY.reshape(len(testY)*len(testY[0]),)\n",
    "# pd.DataFrame(pre).to_csv('pre.csv')\n",
    "# pd.DataFrame(ori).to_csv('ori.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# pre = trainPredict.reshape(len(trainPredict)*len(trainPredict[0]),)\n",
    "# ori = trainY.reshape(len(trainY)*len(trainY[0]),)\n",
    "\n",
    "\n",
    "\n",
    "pre = testPredict.reshape(len(testPredict)*len(testPredict[0]),)\n",
    "ori = testY.reshape(len(testY)*len(testY[0]),)\n",
    "plt.figure(figsize=(10,6))\n",
    "# plt.plot(pre[600:800],color='r')\n",
    "# plt.plot(ori[600:800],color='g')\n",
    "\n",
    "plt.plot(pre,color='r')\n",
    "plt.plot(ori,color='g')\n",
    "plt.plot(pre,color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(pre[600:800],color='r')\n",
    "plt.plot(ori[600:800],color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
