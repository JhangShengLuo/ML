{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "import sklearn.linear_model as lm\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense,Reshape,advanced_activations\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import tensorflow\n",
    "import keras\n",
    "import math\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module keras.layers.advanced_activations in keras.layers:\n",
      "\n",
      "NAME\n",
      "    keras.layers.advanced_activations\n",
      "\n",
      "FILE\n",
      "    /Users/Jackie/anaconda/lib/python2.7/site-packages/keras/layers/advanced_activations.py\n",
      "\n",
      "CLASSES\n",
      "    keras.engine.topology.Layer(__builtin__.object)\n",
      "        ELU\n",
      "        LeakyReLU\n",
      "        PReLU\n",
      "        ParametricSoftplus\n",
      "        SReLU\n",
      "        ThresholdedReLU\n",
      "    \n",
      "    class ELU(keras.engine.topology.Layer)\n",
      "     |  Exponential Linear Unit.\n",
      "     |  \n",
      "     |  It follows:\n",
      "     |  `f(x) =  alpha * (exp(x) - 1.) for x < 0`,\n",
      "     |  `f(x) = x for x >= 0`.\n",
      "     |  \n",
      "     |  # Input shape\n",
      "     |      Arbitrary. Use the keyword argument `input_shape`\n",
      "     |      (tuple of integers, does not include the samples axis)\n",
      "     |      when using this layer as the first layer in a model.\n",
      "     |  \n",
      "     |  # Output shape\n",
      "     |      Same shape as the input.\n",
      "     |  \n",
      "     |  # Arguments\n",
      "     |      alpha: scale for the negative factor.\n",
      "     |  \n",
      "     |  # References\n",
      "     |      - [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)](https://arxiv.org/abs/1511.07289v1)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ELU\n",
      "     |      keras.engine.topology.Layer\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, alpha=1.0, **kwargs)\n",
      "     |  \n",
      "     |  call(self, x, mask=None)\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  __call__(self, x, mask=None)\n",
      "     |      Wrapper around self.call(), for handling\n",
      "     |      internal Keras references.\n",
      "     |      \n",
      "     |      If a Keras tensor is passed:\n",
      "     |          - We call self.add_inbound_node().\n",
      "     |          - If necessary, we `build` the layer to match\n",
      "     |              the _keras_shape of the input(s).\n",
      "     |          - We update the _keras_shape of every input tensor with\n",
      "     |              its new shape (obtained via self.get_output_shape_for).\n",
      "     |              This is done as part of add_inbound_node().\n",
      "     |          - We update the _keras_history of the output tensor(s)\n",
      "     |              with the current layer.\n",
      "     |              This is done as part of add_inbound_node().\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          x: Can be a tensor or list/tuple of tensors.\n",
      "     |          mask: Tensor or list/tuple of tensors.\n",
      "     |  \n",
      "     |  add_inbound_node(self, inbound_layers, node_indices=None, tensor_indices=None)\n",
      "     |      # Arguments\n",
      "     |          inbound_layers: Can be a layer instance\n",
      "     |              or a list/tuple of layer instances.\n",
      "     |          node_indices: Integer (or list of integers).\n",
      "     |              The input layer might have a number of\n",
      "     |              parallel output streams;\n",
      "     |              this is the index of the stream (in the input layer)\n",
      "     |              where to connect the current layer.\n",
      "     |          tensor_indices: Integer or list of integers.\n",
      "     |              The output of the inbound node might be a list/tuple\n",
      "     |              of tensor, and we might only be interested in\n",
      "     |              one specific entry.\n",
      "     |              This index allows you to specify the index of\n",
      "     |              the entry in the output list\n",
      "     |              (if applicable). \"None\" means that we take all outputs\n",
      "     |              (as a list).\n",
      "     |  \n",
      "     |  add_loss(self, losses, inputs=None)\n",
      "     |  \n",
      "     |  add_update(self, updates, inputs=None)\n",
      "     |  \n",
      "     |  add_weight(self, shape, initializer, name=None, trainable=True, regularizer=None, constraint=None)\n",
      "     |      Adds a weight variable to the layer.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          shape: The shape tuple of the weight.\n",
      "     |          initializer: An Initializer instance (callable).\n",
      "     |          trainable: A boolean, whether the weight should\n",
      "     |              be trained via backprop or not (assuming\n",
      "     |              that the layer itself is also trainable).\n",
      "     |          regularizer: An optional Regularizer instance.\n",
      "     |  \n",
      "     |  assert_input_compatibility(self, input)\n",
      "     |      This checks that the tensor(s) `input`\n",
      "     |      verify the input assumptions of the layer\n",
      "     |      (if any). If not, exceptions are raised.\n",
      "     |  \n",
      "     |  build(self, input_shape)\n",
      "     |      Creates the layer weights.\n",
      "     |      Must be implemented on all layers that have weights.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input_shape: Keras tensor (future input to layer)\n",
      "     |              or list/tuple of Keras tensors to reference\n",
      "     |              for weight shape computations.\n",
      "     |  \n",
      "     |  compute_mask(self, input, input_mask=None)\n",
      "     |      Computes an output masking tensor, given an input tensor\n",
      "     |      (or list thereof) and an input mask (or list thereof).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input: Tensor or list of tensors.\n",
      "     |          input_mask: Tensor or list of tensors.\n",
      "     |      \n",
      "     |      # Returns\n",
      "     |          None or a tensor (or list of tensors,\n",
      "     |              one per output tensor of the layer).\n",
      "     |  \n",
      "     |  count_params(self)\n",
      "     |      Returns the total number of floats (or ints)\n",
      "     |      composing the weights of the layer.\n",
      "     |  \n",
      "     |  create_input_layer(self, batch_input_shape, input_dtype=None, name=None)\n",
      "     |  \n",
      "     |  get_input_at(self, node_index)\n",
      "     |      Retrieves the input tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_input_mask_at(self, node_index)\n",
      "     |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_input_shape_at(self, node_index)\n",
      "     |      Retrieves the input shape(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_losses_for(self, inputs)\n",
      "     |  \n",
      "     |  get_output_at(self, node_index)\n",
      "     |      Retrieves the output tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_mask_at(self, node_index)\n",
      "     |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_shape_at(self, node_index)\n",
      "     |      Retrieves the output shape(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_shape_for(self, input_shape)\n",
      "     |      Computes the output shape of the layer given\n",
      "     |      an input shape (assumes that the layer will be built\n",
      "     |      to match that input shape).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input_shape: Shape tuple (tuple of integers)\n",
      "     |              or list of shape tuples (one per output tensor of the layer).\n",
      "     |              Shape tuples can include None for free dimensions,\n",
      "     |              instead of an integer.\n",
      "     |  \n",
      "     |  get_updates_for(self, inputs)\n",
      "     |  \n",
      "     |  get_weights(self)\n",
      "     |      Returns the current weights of the layer,\n",
      "     |      as a list of numpy arrays.\n",
      "     |  \n",
      "     |  set_weights(self, weights)\n",
      "     |      Sets the weights of the layer, from Numpy arrays.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          weights: a list of Numpy arrays. The number\n",
      "     |              of arrays and their shape must match\n",
      "     |              number of the dimensions of the weights\n",
      "     |              of the layer (i.e. it should match the\n",
      "     |              output of `get_weights`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  from_config(cls, config) from __builtin__.type\n",
      "     |      This method is the reverse of get_config,\n",
      "     |      capable of instantiating the same layer from the config\n",
      "     |      dictionary. It does not handle layer connectivity\n",
      "     |      (handled by Container), nor weights (handled by `set_weights`).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          config: A Python dictionary, typically the\n",
      "     |              output of get_config.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  input\n",
      "     |      Retrieves the input tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  input_mask\n",
      "     |      Retrieves the input mask tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  input_shape\n",
      "     |      Retrieves the input shape tuple(s) of a layer. Only applicable\n",
      "     |      if the layer has one inbound node,\n",
      "     |      or if all inbound nodes have the same input shape.\n",
      "     |  \n",
      "     |  non_trainable_weights\n",
      "     |  \n",
      "     |  output\n",
      "     |      Retrieves the output tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  output_mask\n",
      "     |      Retrieves the output mask tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  output_shape\n",
      "     |      Retrieves the output shape tuple(s) of a layer. Only applicable\n",
      "     |      if the layer has one inbound node,\n",
      "     |      or if all inbound nodes have the same output shape.\n",
      "     |  \n",
      "     |  regularizers\n",
      "     |  \n",
      "     |  trainable_weights\n",
      "     |  \n",
      "     |  weights\n",
      "    \n",
      "    class LeakyReLU(keras.engine.topology.Layer)\n",
      "     |  Leaky version of a Rectified Linear Unit.\n",
      "     |  \n",
      "     |  It allows a small gradient when the unit is not active:\n",
      "     |  `f(x) = alpha * x for x < 0`,\n",
      "     |  `f(x) = x for x >= 0`.\n",
      "     |  \n",
      "     |  # Input shape\n",
      "     |      Arbitrary. Use the keyword argument `input_shape`\n",
      "     |      (tuple of integers, does not include the samples axis)\n",
      "     |      when using this layer as the first layer in a model.\n",
      "     |  \n",
      "     |  # Output shape\n",
      "     |      Same shape as the input.\n",
      "     |  \n",
      "     |  # Arguments\n",
      "     |      alpha: float >= 0. Negative slope coefficient.\n",
      "     |  \n",
      "     |  # References\n",
      "     |      - [Rectifier Nonlinearities Improve Neural Network Acoustic Models](https://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LeakyReLU\n",
      "     |      keras.engine.topology.Layer\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, alpha=0.3, **kwargs)\n",
      "     |  \n",
      "     |  call(self, x, mask=None)\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  __call__(self, x, mask=None)\n",
      "     |      Wrapper around self.call(), for handling\n",
      "     |      internal Keras references.\n",
      "     |      \n",
      "     |      If a Keras tensor is passed:\n",
      "     |          - We call self.add_inbound_node().\n",
      "     |          - If necessary, we `build` the layer to match\n",
      "     |              the _keras_shape of the input(s).\n",
      "     |          - We update the _keras_shape of every input tensor with\n",
      "     |              its new shape (obtained via self.get_output_shape_for).\n",
      "     |              This is done as part of add_inbound_node().\n",
      "     |          - We update the _keras_history of the output tensor(s)\n",
      "     |              with the current layer.\n",
      "     |              This is done as part of add_inbound_node().\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          x: Can be a tensor or list/tuple of tensors.\n",
      "     |          mask: Tensor or list/tuple of tensors.\n",
      "     |  \n",
      "     |  add_inbound_node(self, inbound_layers, node_indices=None, tensor_indices=None)\n",
      "     |      # Arguments\n",
      "     |          inbound_layers: Can be a layer instance\n",
      "     |              or a list/tuple of layer instances.\n",
      "     |          node_indices: Integer (or list of integers).\n",
      "     |              The input layer might have a number of\n",
      "     |              parallel output streams;\n",
      "     |              this is the index of the stream (in the input layer)\n",
      "     |              where to connect the current layer.\n",
      "     |          tensor_indices: Integer or list of integers.\n",
      "     |              The output of the inbound node might be a list/tuple\n",
      "     |              of tensor, and we might only be interested in\n",
      "     |              one specific entry.\n",
      "     |              This index allows you to specify the index of\n",
      "     |              the entry in the output list\n",
      "     |              (if applicable). \"None\" means that we take all outputs\n",
      "     |              (as a list).\n",
      "     |  \n",
      "     |  add_loss(self, losses, inputs=None)\n",
      "     |  \n",
      "     |  add_update(self, updates, inputs=None)\n",
      "     |  \n",
      "     |  add_weight(self, shape, initializer, name=None, trainable=True, regularizer=None, constraint=None)\n",
      "     |      Adds a weight variable to the layer.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          shape: The shape tuple of the weight.\n",
      "     |          initializer: An Initializer instance (callable).\n",
      "     |          trainable: A boolean, whether the weight should\n",
      "     |              be trained via backprop or not (assuming\n",
      "     |              that the layer itself is also trainable).\n",
      "     |          regularizer: An optional Regularizer instance.\n",
      "     |  \n",
      "     |  assert_input_compatibility(self, input)\n",
      "     |      This checks that the tensor(s) `input`\n",
      "     |      verify the input assumptions of the layer\n",
      "     |      (if any). If not, exceptions are raised.\n",
      "     |  \n",
      "     |  build(self, input_shape)\n",
      "     |      Creates the layer weights.\n",
      "     |      Must be implemented on all layers that have weights.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input_shape: Keras tensor (future input to layer)\n",
      "     |              or list/tuple of Keras tensors to reference\n",
      "     |              for weight shape computations.\n",
      "     |  \n",
      "     |  compute_mask(self, input, input_mask=None)\n",
      "     |      Computes an output masking tensor, given an input tensor\n",
      "     |      (or list thereof) and an input mask (or list thereof).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input: Tensor or list of tensors.\n",
      "     |          input_mask: Tensor or list of tensors.\n",
      "     |      \n",
      "     |      # Returns\n",
      "     |          None or a tensor (or list of tensors,\n",
      "     |              one per output tensor of the layer).\n",
      "     |  \n",
      "     |  count_params(self)\n",
      "     |      Returns the total number of floats (or ints)\n",
      "     |      composing the weights of the layer.\n",
      "     |  \n",
      "     |  create_input_layer(self, batch_input_shape, input_dtype=None, name=None)\n",
      "     |  \n",
      "     |  get_input_at(self, node_index)\n",
      "     |      Retrieves the input tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_input_mask_at(self, node_index)\n",
      "     |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_input_shape_at(self, node_index)\n",
      "     |      Retrieves the input shape(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_losses_for(self, inputs)\n",
      "     |  \n",
      "     |  get_output_at(self, node_index)\n",
      "     |      Retrieves the output tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_mask_at(self, node_index)\n",
      "     |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_shape_at(self, node_index)\n",
      "     |      Retrieves the output shape(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_shape_for(self, input_shape)\n",
      "     |      Computes the output shape of the layer given\n",
      "     |      an input shape (assumes that the layer will be built\n",
      "     |      to match that input shape).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input_shape: Shape tuple (tuple of integers)\n",
      "     |              or list of shape tuples (one per output tensor of the layer).\n",
      "     |              Shape tuples can include None for free dimensions,\n",
      "     |              instead of an integer.\n",
      "     |  \n",
      "     |  get_updates_for(self, inputs)\n",
      "     |  \n",
      "     |  get_weights(self)\n",
      "     |      Returns the current weights of the layer,\n",
      "     |      as a list of numpy arrays.\n",
      "     |  \n",
      "     |  set_weights(self, weights)\n",
      "     |      Sets the weights of the layer, from Numpy arrays.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          weights: a list of Numpy arrays. The number\n",
      "     |              of arrays and their shape must match\n",
      "     |              number of the dimensions of the weights\n",
      "     |              of the layer (i.e. it should match the\n",
      "     |              output of `get_weights`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  from_config(cls, config) from __builtin__.type\n",
      "     |      This method is the reverse of get_config,\n",
      "     |      capable of instantiating the same layer from the config\n",
      "     |      dictionary. It does not handle layer connectivity\n",
      "     |      (handled by Container), nor weights (handled by `set_weights`).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          config: A Python dictionary, typically the\n",
      "     |              output of get_config.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  input\n",
      "     |      Retrieves the input tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  input_mask\n",
      "     |      Retrieves the input mask tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  input_shape\n",
      "     |      Retrieves the input shape tuple(s) of a layer. Only applicable\n",
      "     |      if the layer has one inbound node,\n",
      "     |      or if all inbound nodes have the same input shape.\n",
      "     |  \n",
      "     |  non_trainable_weights\n",
      "     |  \n",
      "     |  output\n",
      "     |      Retrieves the output tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  output_mask\n",
      "     |      Retrieves the output mask tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  output_shape\n",
      "     |      Retrieves the output shape tuple(s) of a layer. Only applicable\n",
      "     |      if the layer has one inbound node,\n",
      "     |      or if all inbound nodes have the same output shape.\n",
      "     |  \n",
      "     |  regularizers\n",
      "     |  \n",
      "     |  trainable_weights\n",
      "     |  \n",
      "     |  weights\n",
      "    \n",
      "    class PReLU(keras.engine.topology.Layer)\n",
      "     |  Parametric Rectified Linear Unit.\n",
      "     |  \n",
      "     |  It follows:\n",
      "     |  `f(x) = alphas * x for x < 0`,\n",
      "     |  `f(x) = x for x >= 0`,\n",
      "     |  where `alphas` is a learned array with the same shape as x.\n",
      "     |  \n",
      "     |  # Input shape\n",
      "     |      Arbitrary. Use the keyword argument `input_shape`\n",
      "     |      (tuple of integers, does not include the samples axis)\n",
      "     |      when using this layer as the first layer in a model.\n",
      "     |  \n",
      "     |  # Output shape\n",
      "     |      Same shape as the input.\n",
      "     |  \n",
      "     |  # Arguments\n",
      "     |      init: initialization function for the weights.\n",
      "     |      weights: initial weights, as a list of a single Numpy array.\n",
      "     |      shared_axes: the axes along which to share learnable\n",
      "     |          parameters for the activation function.\n",
      "     |          For example, if the incoming feature maps\n",
      "     |          are from a 2D convolution\n",
      "     |          with output shape `(batch, height, width, channels)`,\n",
      "     |          and you wish to share parameters across space\n",
      "     |          so that each filter only has one set of parameters,\n",
      "     |          set `shared_axes=[1, 2]`.\n",
      "     |  \n",
      "     |  # References\n",
      "     |      - [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PReLU\n",
      "     |      keras.engine.topology.Layer\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, init='zero', weights=None, shared_axes=None, **kwargs)\n",
      "     |  \n",
      "     |  build(self, input_shape)\n",
      "     |  \n",
      "     |  call(self, x, mask=None)\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  __call__(self, x, mask=None)\n",
      "     |      Wrapper around self.call(), for handling\n",
      "     |      internal Keras references.\n",
      "     |      \n",
      "     |      If a Keras tensor is passed:\n",
      "     |          - We call self.add_inbound_node().\n",
      "     |          - If necessary, we `build` the layer to match\n",
      "     |              the _keras_shape of the input(s).\n",
      "     |          - We update the _keras_shape of every input tensor with\n",
      "     |              its new shape (obtained via self.get_output_shape_for).\n",
      "     |              This is done as part of add_inbound_node().\n",
      "     |          - We update the _keras_history of the output tensor(s)\n",
      "     |              with the current layer.\n",
      "     |              This is done as part of add_inbound_node().\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          x: Can be a tensor or list/tuple of tensors.\n",
      "     |          mask: Tensor or list/tuple of tensors.\n",
      "     |  \n",
      "     |  add_inbound_node(self, inbound_layers, node_indices=None, tensor_indices=None)\n",
      "     |      # Arguments\n",
      "     |          inbound_layers: Can be a layer instance\n",
      "     |              or a list/tuple of layer instances.\n",
      "     |          node_indices: Integer (or list of integers).\n",
      "     |              The input layer might have a number of\n",
      "     |              parallel output streams;\n",
      "     |              this is the index of the stream (in the input layer)\n",
      "     |              where to connect the current layer.\n",
      "     |          tensor_indices: Integer or list of integers.\n",
      "     |              The output of the inbound node might be a list/tuple\n",
      "     |              of tensor, and we might only be interested in\n",
      "     |              one specific entry.\n",
      "     |              This index allows you to specify the index of\n",
      "     |              the entry in the output list\n",
      "     |              (if applicable). \"None\" means that we take all outputs\n",
      "     |              (as a list).\n",
      "     |  \n",
      "     |  add_loss(self, losses, inputs=None)\n",
      "     |  \n",
      "     |  add_update(self, updates, inputs=None)\n",
      "     |  \n",
      "     |  add_weight(self, shape, initializer, name=None, trainable=True, regularizer=None, constraint=None)\n",
      "     |      Adds a weight variable to the layer.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          shape: The shape tuple of the weight.\n",
      "     |          initializer: An Initializer instance (callable).\n",
      "     |          trainable: A boolean, whether the weight should\n",
      "     |              be trained via backprop or not (assuming\n",
      "     |              that the layer itself is also trainable).\n",
      "     |          regularizer: An optional Regularizer instance.\n",
      "     |  \n",
      "     |  assert_input_compatibility(self, input)\n",
      "     |      This checks that the tensor(s) `input`\n",
      "     |      verify the input assumptions of the layer\n",
      "     |      (if any). If not, exceptions are raised.\n",
      "     |  \n",
      "     |  compute_mask(self, input, input_mask=None)\n",
      "     |      Computes an output masking tensor, given an input tensor\n",
      "     |      (or list thereof) and an input mask (or list thereof).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input: Tensor or list of tensors.\n",
      "     |          input_mask: Tensor or list of tensors.\n",
      "     |      \n",
      "     |      # Returns\n",
      "     |          None or a tensor (or list of tensors,\n",
      "     |              one per output tensor of the layer).\n",
      "     |  \n",
      "     |  count_params(self)\n",
      "     |      Returns the total number of floats (or ints)\n",
      "     |      composing the weights of the layer.\n",
      "     |  \n",
      "     |  create_input_layer(self, batch_input_shape, input_dtype=None, name=None)\n",
      "     |  \n",
      "     |  get_input_at(self, node_index)\n",
      "     |      Retrieves the input tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_input_mask_at(self, node_index)\n",
      "     |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_input_shape_at(self, node_index)\n",
      "     |      Retrieves the input shape(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_losses_for(self, inputs)\n",
      "     |  \n",
      "     |  get_output_at(self, node_index)\n",
      "     |      Retrieves the output tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_mask_at(self, node_index)\n",
      "     |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_shape_at(self, node_index)\n",
      "     |      Retrieves the output shape(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_shape_for(self, input_shape)\n",
      "     |      Computes the output shape of the layer given\n",
      "     |      an input shape (assumes that the layer will be built\n",
      "     |      to match that input shape).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input_shape: Shape tuple (tuple of integers)\n",
      "     |              or list of shape tuples (one per output tensor of the layer).\n",
      "     |              Shape tuples can include None for free dimensions,\n",
      "     |              instead of an integer.\n",
      "     |  \n",
      "     |  get_updates_for(self, inputs)\n",
      "     |  \n",
      "     |  get_weights(self)\n",
      "     |      Returns the current weights of the layer,\n",
      "     |      as a list of numpy arrays.\n",
      "     |  \n",
      "     |  set_weights(self, weights)\n",
      "     |      Sets the weights of the layer, from Numpy arrays.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          weights: a list of Numpy arrays. The number\n",
      "     |              of arrays and their shape must match\n",
      "     |              number of the dimensions of the weights\n",
      "     |              of the layer (i.e. it should match the\n",
      "     |              output of `get_weights`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  from_config(cls, config) from __builtin__.type\n",
      "     |      This method is the reverse of get_config,\n",
      "     |      capable of instantiating the same layer from the config\n",
      "     |      dictionary. It does not handle layer connectivity\n",
      "     |      (handled by Container), nor weights (handled by `set_weights`).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          config: A Python dictionary, typically the\n",
      "     |              output of get_config.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  input\n",
      "     |      Retrieves the input tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  input_mask\n",
      "     |      Retrieves the input mask tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  input_shape\n",
      "     |      Retrieves the input shape tuple(s) of a layer. Only applicable\n",
      "     |      if the layer has one inbound node,\n",
      "     |      or if all inbound nodes have the same input shape.\n",
      "     |  \n",
      "     |  non_trainable_weights\n",
      "     |  \n",
      "     |  output\n",
      "     |      Retrieves the output tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  output_mask\n",
      "     |      Retrieves the output mask tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  output_shape\n",
      "     |      Retrieves the output shape tuple(s) of a layer. Only applicable\n",
      "     |      if the layer has one inbound node,\n",
      "     |      or if all inbound nodes have the same output shape.\n",
      "     |  \n",
      "     |  regularizers\n",
      "     |  \n",
      "     |  trainable_weights\n",
      "     |  \n",
      "     |  weights\n",
      "    \n",
      "    class ParametricSoftplus(keras.engine.topology.Layer)\n",
      "     |  Parametric Softplus.\n",
      "     |  \n",
      "     |  It follows:\n",
      "     |  `f(x) = alpha * log(1 + exp(beta * x))`\n",
      "     |  \n",
      "     |  # Input shape\n",
      "     |      Arbitrary. Use the keyword argument `input_shape`\n",
      "     |      (tuple of integers, does not include the samples axis)\n",
      "     |      when using this layer as the first layer in a model.\n",
      "     |  \n",
      "     |  # Output shape\n",
      "     |      Same shape as the input.\n",
      "     |  \n",
      "     |  # Arguments\n",
      "     |      alpha_init: float. Initial value of the alpha weights.\n",
      "     |      beta_init: float. Initial values of the beta weights.\n",
      "     |      weights: initial weights, as a list of 2 numpy arrays.\n",
      "     |      shared_axes: the axes along which to share learnable\n",
      "     |          parameters for the activation function.\n",
      "     |          For example, if the incoming feature maps\n",
      "     |          are from a 2D convolution\n",
      "     |          with output shape `(batch, height, width, channels)`,\n",
      "     |          and you wish to share parameters across space\n",
      "     |          so that each filter only has one set of parameters,\n",
      "     |          set `shared_axes=[1, 2]`.\n",
      "     |  \n",
      "     |  # References\n",
      "     |      - [Inferring Nonlinear Neuronal Computation Based on Physiologically Plausible Inputs](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003143)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ParametricSoftplus\n",
      "     |      keras.engine.topology.Layer\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, alpha_init=0.2, beta_init=5.0, weights=None, shared_axes=None, **kwargs)\n",
      "     |  \n",
      "     |  build(self, input_shape)\n",
      "     |  \n",
      "     |  call(self, x, mask=None)\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  __call__(self, x, mask=None)\n",
      "     |      Wrapper around self.call(), for handling\n",
      "     |      internal Keras references.\n",
      "     |      \n",
      "     |      If a Keras tensor is passed:\n",
      "     |          - We call self.add_inbound_node().\n",
      "     |          - If necessary, we `build` the layer to match\n",
      "     |              the _keras_shape of the input(s).\n",
      "     |          - We update the _keras_shape of every input tensor with\n",
      "     |              its new shape (obtained via self.get_output_shape_for).\n",
      "     |              This is done as part of add_inbound_node().\n",
      "     |          - We update the _keras_history of the output tensor(s)\n",
      "     |              with the current layer.\n",
      "     |              This is done as part of add_inbound_node().\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          x: Can be a tensor or list/tuple of tensors.\n",
      "     |          mask: Tensor or list/tuple of tensors.\n",
      "     |  \n",
      "     |  add_inbound_node(self, inbound_layers, node_indices=None, tensor_indices=None)\n",
      "     |      # Arguments\n",
      "     |          inbound_layers: Can be a layer instance\n",
      "     |              or a list/tuple of layer instances.\n",
      "     |          node_indices: Integer (or list of integers).\n",
      "     |              The input layer might have a number of\n",
      "     |              parallel output streams;\n",
      "     |              this is the index of the stream (in the input layer)\n",
      "     |              where to connect the current layer.\n",
      "     |          tensor_indices: Integer or list of integers.\n",
      "     |              The output of the inbound node might be a list/tuple\n",
      "     |              of tensor, and we might only be interested in\n",
      "     |              one specific entry.\n",
      "     |              This index allows you to specify the index of\n",
      "     |              the entry in the output list\n",
      "     |              (if applicable). \"None\" means that we take all outputs\n",
      "     |              (as a list).\n",
      "     |  \n",
      "     |  add_loss(self, losses, inputs=None)\n",
      "     |  \n",
      "     |  add_update(self, updates, inputs=None)\n",
      "     |  \n",
      "     |  add_weight(self, shape, initializer, name=None, trainable=True, regularizer=None, constraint=None)\n",
      "     |      Adds a weight variable to the layer.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          shape: The shape tuple of the weight.\n",
      "     |          initializer: An Initializer instance (callable).\n",
      "     |          trainable: A boolean, whether the weight should\n",
      "     |              be trained via backprop or not (assuming\n",
      "     |              that the layer itself is also trainable).\n",
      "     |          regularizer: An optional Regularizer instance.\n",
      "     |  \n",
      "     |  assert_input_compatibility(self, input)\n",
      "     |      This checks that the tensor(s) `input`\n",
      "     |      verify the input assumptions of the layer\n",
      "     |      (if any). If not, exceptions are raised.\n",
      "     |  \n",
      "     |  compute_mask(self, input, input_mask=None)\n",
      "     |      Computes an output masking tensor, given an input tensor\n",
      "     |      (or list thereof) and an input mask (or list thereof).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input: Tensor or list of tensors.\n",
      "     |          input_mask: Tensor or list of tensors.\n",
      "     |      \n",
      "     |      # Returns\n",
      "     |          None or a tensor (or list of tensors,\n",
      "     |              one per output tensor of the layer).\n",
      "     |  \n",
      "     |  count_params(self)\n",
      "     |      Returns the total number of floats (or ints)\n",
      "     |      composing the weights of the layer.\n",
      "     |  \n",
      "     |  create_input_layer(self, batch_input_shape, input_dtype=None, name=None)\n",
      "     |  \n",
      "     |  get_input_at(self, node_index)\n",
      "     |      Retrieves the input tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_input_mask_at(self, node_index)\n",
      "     |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_input_shape_at(self, node_index)\n",
      "     |      Retrieves the input shape(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_losses_for(self, inputs)\n",
      "     |  \n",
      "     |  get_output_at(self, node_index)\n",
      "     |      Retrieves the output tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_mask_at(self, node_index)\n",
      "     |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_shape_at(self, node_index)\n",
      "     |      Retrieves the output shape(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_shape_for(self, input_shape)\n",
      "     |      Computes the output shape of the layer given\n",
      "     |      an input shape (assumes that the layer will be built\n",
      "     |      to match that input shape).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input_shape: Shape tuple (tuple of integers)\n",
      "     |              or list of shape tuples (one per output tensor of the layer).\n",
      "     |              Shape tuples can include None for free dimensions,\n",
      "     |              instead of an integer.\n",
      "     |  \n",
      "     |  get_updates_for(self, inputs)\n",
      "     |  \n",
      "     |  get_weights(self)\n",
      "     |      Returns the current weights of the layer,\n",
      "     |      as a list of numpy arrays.\n",
      "     |  \n",
      "     |  set_weights(self, weights)\n",
      "     |      Sets the weights of the layer, from Numpy arrays.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          weights: a list of Numpy arrays. The number\n",
      "     |              of arrays and their shape must match\n",
      "     |              number of the dimensions of the weights\n",
      "     |              of the layer (i.e. it should match the\n",
      "     |              output of `get_weights`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  from_config(cls, config) from __builtin__.type\n",
      "     |      This method is the reverse of get_config,\n",
      "     |      capable of instantiating the same layer from the config\n",
      "     |      dictionary. It does not handle layer connectivity\n",
      "     |      (handled by Container), nor weights (handled by `set_weights`).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          config: A Python dictionary, typically the\n",
      "     |              output of get_config.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  input\n",
      "     |      Retrieves the input tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  input_mask\n",
      "     |      Retrieves the input mask tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  input_shape\n",
      "     |      Retrieves the input shape tuple(s) of a layer. Only applicable\n",
      "     |      if the layer has one inbound node,\n",
      "     |      or if all inbound nodes have the same input shape.\n",
      "     |  \n",
      "     |  non_trainable_weights\n",
      "     |  \n",
      "     |  output\n",
      "     |      Retrieves the output tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  output_mask\n",
      "     |      Retrieves the output mask tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  output_shape\n",
      "     |      Retrieves the output shape tuple(s) of a layer. Only applicable\n",
      "     |      if the layer has one inbound node,\n",
      "     |      or if all inbound nodes have the same output shape.\n",
      "     |  \n",
      "     |  regularizers\n",
      "     |  \n",
      "     |  trainable_weights\n",
      "     |  \n",
      "     |  weights\n",
      "    \n",
      "    class SReLU(keras.engine.topology.Layer)\n",
      "     |  S-shaped Rectified Linear Unit.\n",
      "     |  \n",
      "     |  It follows:\n",
      "     |  `f(x) = t^r + a^r(x - t^r) for x >= t^r`,\n",
      "     |  `f(x) = x for t^r > x > t^l`,\n",
      "     |  `f(x) = t^l + a^l(x - t^l) for x <= t^l`.\n",
      "     |  \n",
      "     |  # Input shape\n",
      "     |      Arbitrary. Use the keyword argument `input_shape`\n",
      "     |      (tuple of integers, does not include the samples axis)\n",
      "     |      when using this layer as the first layer in a model.\n",
      "     |  \n",
      "     |  # Output shape\n",
      "     |      Same shape as the input.\n",
      "     |  \n",
      "     |  # Arguments\n",
      "     |      t_left_init: initialization function for the left part intercept\n",
      "     |      a_left_init: initialization function for the left part slope\n",
      "     |      t_right_init: initialization function for the right part intercept\n",
      "     |      a_right_init: initialization function for the right part slope\n",
      "     |      shared_axes: the axes along which to share learnable\n",
      "     |          parameters for the activation function.\n",
      "     |          For example, if the incoming feature maps\n",
      "     |          are from a 2D convolution\n",
      "     |          with output shape `(batch, height, width, channels)`,\n",
      "     |          and you wish to share parameters across space\n",
      "     |          so that each filter only has one set of parameters,\n",
      "     |          set `shared_axes=[1, 2]`.\n",
      "     |  \n",
      "     |  # References\n",
      "     |      - [Deep Learning with S-shaped Rectified Linear Activation Units](http://arxiv.org/abs/1512.07030)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SReLU\n",
      "     |      keras.engine.topology.Layer\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, t_left_init='zero', a_left_init='glorot_uniform', t_right_init='glorot_uniform', a_right_init='one', shared_axes=None, **kwargs)\n",
      "     |  \n",
      "     |  build(self, input_shape)\n",
      "     |  \n",
      "     |  call(self, x, mask=None)\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  __call__(self, x, mask=None)\n",
      "     |      Wrapper around self.call(), for handling\n",
      "     |      internal Keras references.\n",
      "     |      \n",
      "     |      If a Keras tensor is passed:\n",
      "     |          - We call self.add_inbound_node().\n",
      "     |          - If necessary, we `build` the layer to match\n",
      "     |              the _keras_shape of the input(s).\n",
      "     |          - We update the _keras_shape of every input tensor with\n",
      "     |              its new shape (obtained via self.get_output_shape_for).\n",
      "     |              This is done as part of add_inbound_node().\n",
      "     |          - We update the _keras_history of the output tensor(s)\n",
      "     |              with the current layer.\n",
      "     |              This is done as part of add_inbound_node().\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          x: Can be a tensor or list/tuple of tensors.\n",
      "     |          mask: Tensor or list/tuple of tensors.\n",
      "     |  \n",
      "     |  add_inbound_node(self, inbound_layers, node_indices=None, tensor_indices=None)\n",
      "     |      # Arguments\n",
      "     |          inbound_layers: Can be a layer instance\n",
      "     |              or a list/tuple of layer instances.\n",
      "     |          node_indices: Integer (or list of integers).\n",
      "     |              The input layer might have a number of\n",
      "     |              parallel output streams;\n",
      "     |              this is the index of the stream (in the input layer)\n",
      "     |              where to connect the current layer.\n",
      "     |          tensor_indices: Integer or list of integers.\n",
      "     |              The output of the inbound node might be a list/tuple\n",
      "     |              of tensor, and we might only be interested in\n",
      "     |              one specific entry.\n",
      "     |              This index allows you to specify the index of\n",
      "     |              the entry in the output list\n",
      "     |              (if applicable). \"None\" means that we take all outputs\n",
      "     |              (as a list).\n",
      "     |  \n",
      "     |  add_loss(self, losses, inputs=None)\n",
      "     |  \n",
      "     |  add_update(self, updates, inputs=None)\n",
      "     |  \n",
      "     |  add_weight(self, shape, initializer, name=None, trainable=True, regularizer=None, constraint=None)\n",
      "     |      Adds a weight variable to the layer.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          shape: The shape tuple of the weight.\n",
      "     |          initializer: An Initializer instance (callable).\n",
      "     |          trainable: A boolean, whether the weight should\n",
      "     |              be trained via backprop or not (assuming\n",
      "     |              that the layer itself is also trainable).\n",
      "     |          regularizer: An optional Regularizer instance.\n",
      "     |  \n",
      "     |  assert_input_compatibility(self, input)\n",
      "     |      This checks that the tensor(s) `input`\n",
      "     |      verify the input assumptions of the layer\n",
      "     |      (if any). If not, exceptions are raised.\n",
      "     |  \n",
      "     |  compute_mask(self, input, input_mask=None)\n",
      "     |      Computes an output masking tensor, given an input tensor\n",
      "     |      (or list thereof) and an input mask (or list thereof).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input: Tensor or list of tensors.\n",
      "     |          input_mask: Tensor or list of tensors.\n",
      "     |      \n",
      "     |      # Returns\n",
      "     |          None or a tensor (or list of tensors,\n",
      "     |              one per output tensor of the layer).\n",
      "     |  \n",
      "     |  count_params(self)\n",
      "     |      Returns the total number of floats (or ints)\n",
      "     |      composing the weights of the layer.\n",
      "     |  \n",
      "     |  create_input_layer(self, batch_input_shape, input_dtype=None, name=None)\n",
      "     |  \n",
      "     |  get_input_at(self, node_index)\n",
      "     |      Retrieves the input tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_input_mask_at(self, node_index)\n",
      "     |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_input_shape_at(self, node_index)\n",
      "     |      Retrieves the input shape(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_losses_for(self, inputs)\n",
      "     |  \n",
      "     |  get_output_at(self, node_index)\n",
      "     |      Retrieves the output tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_mask_at(self, node_index)\n",
      "     |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_shape_at(self, node_index)\n",
      "     |      Retrieves the output shape(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_shape_for(self, input_shape)\n",
      "     |      Computes the output shape of the layer given\n",
      "     |      an input shape (assumes that the layer will be built\n",
      "     |      to match that input shape).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input_shape: Shape tuple (tuple of integers)\n",
      "     |              or list of shape tuples (one per output tensor of the layer).\n",
      "     |              Shape tuples can include None for free dimensions,\n",
      "     |              instead of an integer.\n",
      "     |  \n",
      "     |  get_updates_for(self, inputs)\n",
      "     |  \n",
      "     |  get_weights(self)\n",
      "     |      Returns the current weights of the layer,\n",
      "     |      as a list of numpy arrays.\n",
      "     |  \n",
      "     |  set_weights(self, weights)\n",
      "     |      Sets the weights of the layer, from Numpy arrays.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          weights: a list of Numpy arrays. The number\n",
      "     |              of arrays and their shape must match\n",
      "     |              number of the dimensions of the weights\n",
      "     |              of the layer (i.e. it should match the\n",
      "     |              output of `get_weights`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  from_config(cls, config) from __builtin__.type\n",
      "     |      This method is the reverse of get_config,\n",
      "     |      capable of instantiating the same layer from the config\n",
      "     |      dictionary. It does not handle layer connectivity\n",
      "     |      (handled by Container), nor weights (handled by `set_weights`).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          config: A Python dictionary, typically the\n",
      "     |              output of get_config.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  input\n",
      "     |      Retrieves the input tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  input_mask\n",
      "     |      Retrieves the input mask tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  input_shape\n",
      "     |      Retrieves the input shape tuple(s) of a layer. Only applicable\n",
      "     |      if the layer has one inbound node,\n",
      "     |      or if all inbound nodes have the same input shape.\n",
      "     |  \n",
      "     |  non_trainable_weights\n",
      "     |  \n",
      "     |  output\n",
      "     |      Retrieves the output tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  output_mask\n",
      "     |      Retrieves the output mask tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  output_shape\n",
      "     |      Retrieves the output shape tuple(s) of a layer. Only applicable\n",
      "     |      if the layer has one inbound node,\n",
      "     |      or if all inbound nodes have the same output shape.\n",
      "     |  \n",
      "     |  regularizers\n",
      "     |  \n",
      "     |  trainable_weights\n",
      "     |  \n",
      "     |  weights\n",
      "    \n",
      "    class ThresholdedReLU(keras.engine.topology.Layer)\n",
      "     |  Thresholded Rectified Linear Unit.\n",
      "     |  \n",
      "     |  It follows:\n",
      "     |  `f(x) = x for x > theta`,\n",
      "     |  `f(x) = 0 otherwise`.\n",
      "     |  \n",
      "     |  # Input shape\n",
      "     |      Arbitrary. Use the keyword argument `input_shape`\n",
      "     |      (tuple of integers, does not include the samples axis)\n",
      "     |      when using this layer as the first layer in a model.\n",
      "     |  \n",
      "     |  # Output shape\n",
      "     |      Same shape as the input.\n",
      "     |  \n",
      "     |  # Arguments\n",
      "     |      theta: float >= 0. Threshold location of activation.\n",
      "     |  \n",
      "     |  # References\n",
      "     |      - [Zero-Bias Autoencoders and the Benefits of Co-Adapting Features](http://arxiv.org/abs/1402.3337)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ThresholdedReLU\n",
      "     |      keras.engine.topology.Layer\n",
      "     |      __builtin__.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, theta=1.0, **kwargs)\n",
      "     |  \n",
      "     |  call(self, x, mask=None)\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  __call__(self, x, mask=None)\n",
      "     |      Wrapper around self.call(), for handling\n",
      "     |      internal Keras references.\n",
      "     |      \n",
      "     |      If a Keras tensor is passed:\n",
      "     |          - We call self.add_inbound_node().\n",
      "     |          - If necessary, we `build` the layer to match\n",
      "     |              the _keras_shape of the input(s).\n",
      "     |          - We update the _keras_shape of every input tensor with\n",
      "     |              its new shape (obtained via self.get_output_shape_for).\n",
      "     |              This is done as part of add_inbound_node().\n",
      "     |          - We update the _keras_history of the output tensor(s)\n",
      "     |              with the current layer.\n",
      "     |              This is done as part of add_inbound_node().\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          x: Can be a tensor or list/tuple of tensors.\n",
      "     |          mask: Tensor or list/tuple of tensors.\n",
      "     |  \n",
      "     |  add_inbound_node(self, inbound_layers, node_indices=None, tensor_indices=None)\n",
      "     |      # Arguments\n",
      "     |          inbound_layers: Can be a layer instance\n",
      "     |              or a list/tuple of layer instances.\n",
      "     |          node_indices: Integer (or list of integers).\n",
      "     |              The input layer might have a number of\n",
      "     |              parallel output streams;\n",
      "     |              this is the index of the stream (in the input layer)\n",
      "     |              where to connect the current layer.\n",
      "     |          tensor_indices: Integer or list of integers.\n",
      "     |              The output of the inbound node might be a list/tuple\n",
      "     |              of tensor, and we might only be interested in\n",
      "     |              one specific entry.\n",
      "     |              This index allows you to specify the index of\n",
      "     |              the entry in the output list\n",
      "     |              (if applicable). \"None\" means that we take all outputs\n",
      "     |              (as a list).\n",
      "     |  \n",
      "     |  add_loss(self, losses, inputs=None)\n",
      "     |  \n",
      "     |  add_update(self, updates, inputs=None)\n",
      "     |  \n",
      "     |  add_weight(self, shape, initializer, name=None, trainable=True, regularizer=None, constraint=None)\n",
      "     |      Adds a weight variable to the layer.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          shape: The shape tuple of the weight.\n",
      "     |          initializer: An Initializer instance (callable).\n",
      "     |          trainable: A boolean, whether the weight should\n",
      "     |              be trained via backprop or not (assuming\n",
      "     |              that the layer itself is also trainable).\n",
      "     |          regularizer: An optional Regularizer instance.\n",
      "     |  \n",
      "     |  assert_input_compatibility(self, input)\n",
      "     |      This checks that the tensor(s) `input`\n",
      "     |      verify the input assumptions of the layer\n",
      "     |      (if any). If not, exceptions are raised.\n",
      "     |  \n",
      "     |  build(self, input_shape)\n",
      "     |      Creates the layer weights.\n",
      "     |      Must be implemented on all layers that have weights.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input_shape: Keras tensor (future input to layer)\n",
      "     |              or list/tuple of Keras tensors to reference\n",
      "     |              for weight shape computations.\n",
      "     |  \n",
      "     |  compute_mask(self, input, input_mask=None)\n",
      "     |      Computes an output masking tensor, given an input tensor\n",
      "     |      (or list thereof) and an input mask (or list thereof).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input: Tensor or list of tensors.\n",
      "     |          input_mask: Tensor or list of tensors.\n",
      "     |      \n",
      "     |      # Returns\n",
      "     |          None or a tensor (or list of tensors,\n",
      "     |              one per output tensor of the layer).\n",
      "     |  \n",
      "     |  count_params(self)\n",
      "     |      Returns the total number of floats (or ints)\n",
      "     |      composing the weights of the layer.\n",
      "     |  \n",
      "     |  create_input_layer(self, batch_input_shape, input_dtype=None, name=None)\n",
      "     |  \n",
      "     |  get_input_at(self, node_index)\n",
      "     |      Retrieves the input tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_input_mask_at(self, node_index)\n",
      "     |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_input_shape_at(self, node_index)\n",
      "     |      Retrieves the input shape(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_losses_for(self, inputs)\n",
      "     |  \n",
      "     |  get_output_at(self, node_index)\n",
      "     |      Retrieves the output tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_mask_at(self, node_index)\n",
      "     |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_shape_at(self, node_index)\n",
      "     |      Retrieves the output shape(s) of a layer at a given node.\n",
      "     |  \n",
      "     |  get_output_shape_for(self, input_shape)\n",
      "     |      Computes the output shape of the layer given\n",
      "     |      an input shape (assumes that the layer will be built\n",
      "     |      to match that input shape).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          input_shape: Shape tuple (tuple of integers)\n",
      "     |              or list of shape tuples (one per output tensor of the layer).\n",
      "     |              Shape tuples can include None for free dimensions,\n",
      "     |              instead of an integer.\n",
      "     |  \n",
      "     |  get_updates_for(self, inputs)\n",
      "     |  \n",
      "     |  get_weights(self)\n",
      "     |      Returns the current weights of the layer,\n",
      "     |      as a list of numpy arrays.\n",
      "     |  \n",
      "     |  set_weights(self, weights)\n",
      "     |      Sets the weights of the layer, from Numpy arrays.\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          weights: a list of Numpy arrays. The number\n",
      "     |              of arrays and their shape must match\n",
      "     |              number of the dimensions of the weights\n",
      "     |              of the layer (i.e. it should match the\n",
      "     |              output of `get_weights`).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  from_config(cls, config) from __builtin__.type\n",
      "     |      This method is the reverse of get_config,\n",
      "     |      capable of instantiating the same layer from the config\n",
      "     |      dictionary. It does not handle layer connectivity\n",
      "     |      (handled by Container), nor weights (handled by `set_weights`).\n",
      "     |      \n",
      "     |      # Arguments\n",
      "     |          config: A Python dictionary, typically the\n",
      "     |              output of get_config.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  input\n",
      "     |      Retrieves the input tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  input_mask\n",
      "     |      Retrieves the input mask tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  input_shape\n",
      "     |      Retrieves the input shape tuple(s) of a layer. Only applicable\n",
      "     |      if the layer has one inbound node,\n",
      "     |      or if all inbound nodes have the same input shape.\n",
      "     |  \n",
      "     |  non_trainable_weights\n",
      "     |  \n",
      "     |  output\n",
      "     |      Retrieves the output tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  output_mask\n",
      "     |      Retrieves the output mask tensor(s) of a layer (only applicable if\n",
      "     |      the layer has exactly one inbound node, i.e. if it is connected\n",
      "     |      to one incoming layer).\n",
      "     |  \n",
      "     |  output_shape\n",
      "     |      Retrieves the output shape tuple(s) of a layer. Only applicable\n",
      "     |      if the layer has one inbound node,\n",
      "     |      or if all inbound nodes have the same output shape.\n",
      "     |  \n",
      "     |  regularizers\n",
      "     |  \n",
      "     |  trainable_weights\n",
      "     |  \n",
      "     |  weights\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(advanced_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4407, 2171)\n",
      "(4368, 2016)\n",
      "Train Score: 1801.59 MSE (42.45 RMSE)\n",
      "Test Score: 27266.68 MSE (165.13 RMSE)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEACAYAAAC3adEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMBh8+P/NyYtALyl69QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ceb3250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "\n",
    "np.random.seed(7)\n",
    "mldf = pd.read_csv('mltest.csv', engine='python')\n",
    "# First thing first, format data to what we need\n",
    "mltt = mldf.ix[:,[3,4,5,6,8,9,10,7]].copy()\n",
    "mltt.columns = ['a','b','c','d','e','f','g','h'];mltt\n",
    "mltt.replace(to_replace='東',value=1,inplace=True );mltt\n",
    "mltt.c=pd.to_datetime(mltt.c);\n",
    "mltt.c = pd.to_datetime(mltt.c);\n",
    "mltt['weekday'] = mltt['c'].dt.dayofweek;mltt\n",
    "mltt.c= mltt.c.dt.dayofyear;mltt\n",
    "mltt.replace(to_replace='00:00:00',value=0,inplace=True );mltt\n",
    "mltt.replace(to_replace='01:00:00',value=1,inplace=True );mltt\n",
    "mltt.replace(to_replace='02:00:00',value=2,inplace=True );mltt\n",
    "mltt.replace(to_replace='03:00:00',value=3,inplace=True );mltt\n",
    "mltt.replace(to_replace='04:00:00',value=4,inplace=True );mltt\n",
    "mltt.replace(to_replace='05:00:00',value=5,inplace=True );mltt\n",
    "mltt.replace(to_replace='06:00:00',value=6,inplace=True );mltt\n",
    "mltt.replace(to_replace='07:00:00',value=7,inplace=True );mltt\n",
    "mltt.replace(to_replace='08:00:00',value=8,inplace=True );mltt\n",
    "mltt.replace(to_replace='09:00:00',value=9,inplace=True );mltt\n",
    "mltt.replace(to_replace='10:00:00',value=10,inplace=True );mltt\n",
    "mltt.replace(to_replace='11:00:00',value=11,inplace=True );mltt\n",
    "mltt.replace(to_replace='12:00:00',value=12,inplace=True );mltt\n",
    "mltt.replace(to_replace='13:00:00',value=13,inplace=True );mltt\n",
    "mltt.replace(to_replace='14:00:00',value=14,inplace=True );mltt\n",
    "mltt.replace(to_replace='15:00:00',value=15,inplace=True );mltt\n",
    "mltt.replace(to_replace='16:00:00',value=16,inplace=True );mltt\n",
    "mltt.replace(to_replace='17:00:00',value=17,inplace=True );mltt\n",
    "mltt.replace(to_replace='18:00:00',value=18,inplace=True );mltt\n",
    "mltt.replace(to_replace='19:00:00',value=19,inplace=True );mltt\n",
    "mltt.replace(to_replace='20:00:00',value=20,inplace=True );mltt\n",
    "mltt.replace(to_replace='21:00:00',value=21,inplace=True );mltt\n",
    "mltt.replace(to_replace='22:00:00',value=22,inplace=True );mltt\n",
    "mltt.replace(to_replace='23:00:00',value=23,inplace=True );mltt\n",
    "\n",
    "cols =mltt.columns.tolist()\n",
    "mltt= mltt[cols[:3]+cols[-1:]+cols[3:-1]];mltt\n",
    "mltt.columns = ['a','b','c','d','e','f','g','h','i'];mltt\n",
    "\n",
    "mlttva = mltt.values\n",
    "mlttva = mlttva.astype('float32')\n",
    "\n",
    "# seperate train and test data to 67%/33%\n",
    "train_size = int(len(mlttva) * 0.67)\n",
    "test_size = len(mlttva) - train_size\n",
    "train, test = mlttva[0:train_size,:], mlttva[train_size:len(mlttva),:]\n",
    "# check the lenth of data\n",
    "print(len(train), len(test))\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(0,len(dataset)-look_back-1,look_back):\n",
    "        a = dataset[i:(i+look_back), 0:9]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back:i+look_back+look_back, 8])\n",
    "#     return dataX,dataY\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "# magic number\n",
    "look_back = 168\n",
    "# cut off remainder\n",
    "train = train[:-(len(train)%look_back)]\n",
    "test = test[:-(len(test)%look_back)]\n",
    "# check data lenth when cut off remainder\n",
    "print(len(train), len(test))\n",
    "# seperate data to input\"X\" and output\"Y\"\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# create and fit Multilayer Perceptron model\n",
    "model = Sequential()\n",
    "\n",
    "# RESHAPE is  working !!!!! >0<\"\n",
    "model.add(Reshape((look_back*9,), input_shape=(look_back,9)))\n",
    "# Add layers to neruon network\n",
    "model.add(Dense(190,input_dim=(look_back*9), activation='relu'))\n",
    "model.add(Dense(256, init='uniform', activation='relu'))\n",
    "model.add(Dense(look_back))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.fit(trainX, trainY, nb_epoch=168, batch_size=3, verbose=0)\n",
    "\n",
    "\n",
    "# Estimate model performance\n",
    "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, math.sqrt(trainScore)))\n",
    "testScore = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore, math.sqrt(testScore)))\n",
    "\n",
    "# predict result\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# Jackie veriosn plot\n",
    "\n",
    "pre = testPredict.reshape(len(testPredict)*len(testPredict[0]),)\n",
    "ori = testY.reshape(len(testY)*len(testY[0]),)\n",
    "\n",
    "plt.plot(pre[-168:],color='r')\n",
    "plt.plot(ori[-168:],color='g')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save model to hdf5\n",
    "model.save('jackiedl.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(inp):\n",
    "    outp = inp.ix[:,[3,4,5,6,8,9,10,7]].copy()\n",
    "    outp.columns = ['a','b','c','d','e','f','g','h'];outp\n",
    "    outp.replace(to_replace='東',value=1,inplace=True );outp\n",
    "    outp.c=pd.to_datetime(outp.c);\n",
    "    outp['weekday'] = outp['c'].dt.dayofweek;outp\n",
    "    outp.c= outp.c.dt.dayofyear;outp\n",
    "    outp.replace(to_replace='00:00:00',value=0,inplace=True );outp\n",
    "    outp.replace(to_replace='01:00:00',value=1,inplace=True );outp\n",
    "    outp.replace(to_replace='02:00:00',value=2,inplace=True );outp\n",
    "    outp.replace(to_replace='03:00:00',value=3,inplace=True );outp\n",
    "    outp.replace(to_replace='04:00:00',value=4,inplace=True );outp\n",
    "    outp.replace(to_replace='05:00:00',value=5,inplace=True );outp\n",
    "    outp.replace(to_replace='06:00:00',value=6,inplace=True );outp\n",
    "    outp.replace(to_replace='07:00:00',value=7,inplace=True );outp\n",
    "    outp.replace(to_replace='08:00:00',value=8,inplace=True );outp\n",
    "    outp.replace(to_replace='09:00:00',value=9,inplace=True );outp\n",
    "    outp.replace(to_replace='10:00:00',value=10,inplace=True );outp\n",
    "    outp.replace(to_replace='11:00:00',value=11,inplace=True );outp\n",
    "    outp.replace(to_replace='12:00:00',value=12,inplace=True );outp\n",
    "    outp.replace(to_replace='13:00:00',value=13,inplace=True );outp\n",
    "    outp.replace(to_replace='14:00:00',value=14,inplace=True );outp\n",
    "    outp.replace(to_replace='15:00:00',value=15,inplace=True );outp\n",
    "    outp.replace(to_replace='16:00:00',value=16,inplace=True );outp\n",
    "    outp.replace(to_replace='17:00:00',value=17,inplace=True );outp\n",
    "    outp.replace(to_replace='18:00:00',value=18,inplace=True );outp\n",
    "    outp.replace(to_replace='19:00:00',value=19,inplace=True );outp\n",
    "    outp.replace(to_replace='20:00:00',value=20,inplace=True );outp\n",
    "    outp.replace(to_replace='21:00:00',value=21,inplace=True );outp\n",
    "    outp.replace(to_replace='22:00:00',value=22,inplace=True );outp\n",
    "    outp.replace(to_replace='23:00:00',value=23,inplace=True );outp\n",
    "    cols =outp.columns.tolist()\n",
    "    outp= outp[cols[:3]+cols[-1:]+cols[3:-1]];outp\n",
    "    outp.columns = ['a','b','c','d','e','f','g','h','i'];outp\n",
    "    outpp = outp.values\n",
    "    outpp = outpp.astype('float32')\n",
    "    return outpp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD7CAYAAACG50QgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngjCibzAYDCOI/w/k8UrR6yLlQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f72ded0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd.read_csv('realtet.csv',header=None, engine='python')\n",
    "res = pd.read_csv('realresult.csv',header=None, engine='python')\n",
    "\n",
    "testva = np.array([clean(test)])\n",
    "resva = np.array([clean(res)])\n",
    "\n",
    "testvapre= model.predict(testva)\n",
    "prett = testvapre.reshape(len(testvapre)*len(testvapre[0]),)\n",
    "plt.plot(prett,color='r')\n",
    "plt.plot(resva[0][:,-1],color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>27.844992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>44.840790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>-20.214939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>10.156651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>50.554195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>195.815079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>351.060791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>362.963898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>410.215363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>475.942200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>505.723785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>560.066956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>552.702515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>605.288086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>632.820435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>745.713379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>800.537781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>763.782471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>899.395081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>731.203003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>683.149902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "110   27.844992\n",
       "111   44.840790\n",
       "112  -20.214939\n",
       "113   10.156651\n",
       "114   50.554195\n",
       "115  195.815079\n",
       "116  351.060791\n",
       "117  362.963898\n",
       "118  410.215363\n",
       "119  475.942200\n",
       "120  505.723785\n",
       "121  560.066956\n",
       "122  552.702515\n",
       "123  605.288086\n",
       "124  632.820435\n",
       "125  745.713379\n",
       "126  800.537781\n",
       "127  763.782471\n",
       "128  899.395081\n",
       "129  731.203003\n",
       "130  683.149902"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare R LR model\n",
    "predf = pd.DataFrame(pre[-168:]);\n",
    "predf.ix[110:130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.102158</td>\n",
       "      <td>2.835000</td>\n",
       "      <td>122.389999</td>\n",
       "      <td>285.254211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.561161</td>\n",
       "      <td>2.030000</td>\n",
       "      <td>115.759995</td>\n",
       "      <td>181.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.275002</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>104.615005</td>\n",
       "      <td>83.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.080002</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>71.599998</td>\n",
       "      <td>50.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.198000</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>48.910000</td>\n",
       "      <td>46.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35.877270</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>49.955002</td>\n",
       "      <td>34.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.035824</td>\n",
       "      <td>1.325000</td>\n",
       "      <td>96.440002</td>\n",
       "      <td>82.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>37.661953</td>\n",
       "      <td>2.175000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>188.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.084412</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>77.595001</td>\n",
       "      <td>457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.467728</td>\n",
       "      <td>5.410000</td>\n",
       "      <td>105.214996</td>\n",
       "      <td>412.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.118015</td>\n",
       "      <td>8.090000</td>\n",
       "      <td>104.324997</td>\n",
       "      <td>584.211853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.678020</td>\n",
       "      <td>5.730000</td>\n",
       "      <td>99.024994</td>\n",
       "      <td>527.788086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.540739</td>\n",
       "      <td>5.885000</td>\n",
       "      <td>105.220001</td>\n",
       "      <td>452.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.787983</td>\n",
       "      <td>2.505000</td>\n",
       "      <td>53.315002</td>\n",
       "      <td>149.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>32.477173</td>\n",
       "      <td>3.780000</td>\n",
       "      <td>102.699997</td>\n",
       "      <td>406.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>36.204559</td>\n",
       "      <td>6.760000</td>\n",
       "      <td>103.175003</td>\n",
       "      <td>510.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>31.323774</td>\n",
       "      <td>9.555000</td>\n",
       "      <td>113.839996</td>\n",
       "      <td>508.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.282631</td>\n",
       "      <td>11.845000</td>\n",
       "      <td>97.394997</td>\n",
       "      <td>643.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.149353</td>\n",
       "      <td>9.809999</td>\n",
       "      <td>106.500000</td>\n",
       "      <td>671.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>33.200996</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>788.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>34.181252</td>\n",
       "      <td>9.139999</td>\n",
       "      <td>110.139999</td>\n",
       "      <td>719.491455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34.667587</td>\n",
       "      <td>7.555000</td>\n",
       "      <td>105.434998</td>\n",
       "      <td>550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.805168</td>\n",
       "      <td>7.685000</td>\n",
       "      <td>110.540001</td>\n",
       "      <td>623.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>35.010002</td>\n",
       "      <td>6.915000</td>\n",
       "      <td>131.110001</td>\n",
       "      <td>460.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      a    b      c    d     e          f          g           h           i\n",
       "11  2.0  1.0  354.0  0.0   0.0  38.102158   2.835000  122.389999  285.254211\n",
       "12  2.0  1.0  354.0  0.0   1.0  37.561161   2.030000  115.759995  181.000000\n",
       "13  2.0  1.0  354.0  0.0   2.0  38.275002   0.755000  104.615005   83.000000\n",
       "14  2.0  1.0  354.0  0.0   3.0  36.080002   0.275000   71.599998   50.500000\n",
       "15  2.0  1.0  354.0  0.0   4.0  25.198000   1.035000   48.910000   46.500000\n",
       "16  2.0  1.0  354.0  0.0   5.0  35.877270   0.410000   49.955002   34.500000\n",
       "17  2.0  1.0  354.0  0.0   6.0  36.035824   1.325000   96.440002   82.500000\n",
       "18  2.0  1.0  354.0  0.0   7.0  37.661953   2.175000  141.000000  188.500000\n",
       "19  2.0  1.0  354.0  0.0   8.0  33.084412   6.750000   77.595001  457.000000\n",
       "20  2.0  1.0  354.0  0.0   9.0  36.467728   5.410000  105.214996  412.500000\n",
       "21  2.0  1.0  354.0  0.0  10.0  34.118015   8.090000  104.324997  584.211853\n",
       "22  2.0  1.0  354.0  0.0  11.0  36.678020   5.730000   99.024994  527.788086\n",
       "23  2.0  1.0  354.0  0.0  12.0  29.540739   5.885000  105.220001  452.000000\n",
       "24  2.0  1.0  354.0  0.0  13.0  25.787983   2.505000   53.315002  149.500000\n",
       "25  2.0  1.0  354.0  0.0  14.0  32.477173   3.780000  102.699997  406.500000\n",
       "26  2.0  1.0  354.0  0.0  15.0  36.204559   6.760000  103.175003  510.500000\n",
       "27  2.0  1.0  354.0  0.0  16.0  31.323774   9.555000  113.839996  508.000000\n",
       "28  2.0  1.0  354.0  0.0  17.0  30.282631  11.845000   97.394997  643.500000\n",
       "29  2.0  1.0  354.0  0.0  18.0  32.149353   9.809999  106.500000  671.000000\n",
       "30  2.0  1.0  354.0  0.0  19.0  33.200996  12.000000   96.000000  788.500000\n",
       "31  2.0  1.0  354.0  0.0  20.0  34.181252   9.139999  110.139999  719.491455\n",
       "32  2.0  1.0  354.0  0.0  21.0  34.667587   7.555000  105.434998  550.000000\n",
       "33  2.0  1.0  354.0  0.0  22.0  32.805168   7.685000  110.540001  623.500000\n",
       "34  2.0  1.0  354.0  0.0  23.0  35.010002   6.915000  131.110001  460.500000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf = pd.read_csv('R_pre.csv',header=None)\n",
    "\n",
    "\n",
    "todf = pd.DataFrame(test[-168:]);\n",
    "todf.columns=['a','b','c','d','e','f','g','h','i']\n",
    "todf.ix[todf.d == 0,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
